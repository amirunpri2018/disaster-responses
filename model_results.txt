##### Cross Validation Result on Validation Dataset #####

Best Score: 0.616022121873669
Best Parameters: MultiOutputClassifier(estimator=LinearSVC(C=1, class_weight=None, dual=False,
                                          fit_intercept=True,
                                          intercept_scaling=1,
                                          loss='squared_hinge', max_iter=1000,
                                          multi_class='ovr', penalty='l2',
                                          random_state=None, tol=0.0001,
                                          verbose=0),
                      n_jobs=None)
Mean Test f1 Weighted: 0.616022121873669
Mean Test f1 Micro: 0.6525877574349961
Mean Test f1 Samples:0.5033564523980887


##### Model Result in Test Dataset #####

Classification Report: 
{'related': {'precision': 0.8595532319391636, 'recall': 0.9056084126189284, 'f1-score': 0.8819800048768593, 'support': 3994}, 'request': {'precision': 0.762589928057554, 'recall': 0.5668449197860963, 'f1-score': 0.6503067484662576, 'support': 935}, 'offer': {'precision': 0.8333333333333334, 'recall': 0.07575757575757576, 'f1-score': 0.1388888888888889, 'support': 66}, 'aid_related': {'precision': 0.7236842105263158, 'recall': 0.6805682859761687, 'f1-score': 0.7014643363249882, 'support': 2182}, 'medical_help': {'precision': 0.5728643216080402, 'recall': 0.2579185520361991, 'f1-score': 0.35569422776911086, 'support': 442}, 'medical_products': {'precision': 0.6517857142857143, 'recall': 0.25704225352112675, 'f1-score': 0.3686868686868687, 'support': 284}, 'search_and_rescue': {'precision': 0.7083333333333334, 'recall': 0.10240963855421686, 'f1-score': 0.1789473684210526, 'support': 166}, 'security': {'precision': 0.5, 'recall': 0.05303030303030303, 'f1-score': 0.09589041095890412, 'support': 132}, 'military': {'precision': 0.5436893203883495, 'recall': 0.2731707317073171, 'f1-score': 0.36363636363636365, 'support': 205}, 'child_alone': {'precision': 0.8333333333333334, 'recall': 0.1282051282051282, 'f1-score': 0.2222222222222222, 'support': 39}, 'water': {'precision': 0.735632183908046, 'recall': 0.5039370078740157, 'f1-score': 0.5981308411214953, 'support': 381}, 'food': {'precision': 0.8174603174603174, 'recall': 0.6309341500765697, 'f1-score': 0.7121866897147796, 'support': 653}, 'shelter': {'precision': 0.7262247838616714, 'recall': 0.5060240963855421, 'f1-score': 0.5964497041420118, 'support': 498}, 'clothing': {'precision': 0.7719298245614035, 'recall': 0.3283582089552239, 'f1-score': 0.46073298429319365, 'support': 134}, 'money': {'precision': 0.5490196078431373, 'recall': 0.17391304347826086, 'f1-score': 0.2641509433962264, 'support': 161}, 'missing_people': {'precision': 0.5789473684210527, 'recall': 0.12222222222222222, 'f1-score': 0.2018348623853211, 'support': 90}, 'refugees': {'precision': 0.5967741935483871, 'recall': 0.1796116504854369, 'f1-score': 0.27611940298507465, 'support': 206}, 'death': {'precision': 0.8156028368794326, 'recall': 0.4078014184397163, 'f1-score': 0.5437352245862883, 'support': 282}, 'other_aid': {'precision': 0.48220064724919093, 'recall': 0.21015514809590974, 'f1-score': 0.29273084479371314, 'support': 709}, 'infrastructure_related': {'precision': 0.4044943820224719, 'recall': 0.09, 'f1-score': 0.147239263803681, 'support': 400}, 'transport': {'precision': 0.6979166666666666, 'recall': 0.24100719424460432, 'f1-score': 0.358288770053476, 'support': 278}, 'buildings': {'precision': 0.6291390728476821, 'recall': 0.30448717948717946, 'f1-score': 0.41036717062634986, 'support': 312}, 'electricity': {'precision': 0.6470588235294118, 'recall': 0.2129032258064516, 'f1-score': 0.3203883495145631, 'support': 155}, 'tools': {'precision': 0.6, 'recall': 0.03896103896103896, 'f1-score': 0.07317073170731707, 'support': 77}, 'hospitals': {'precision': 0.5, 'recall': 0.045454545454545456, 'f1-score': 0.08333333333333334, 'support': 110}, 'shops': {'precision': 0.75, 'recall': 0.05084745762711865, 'f1-score': 0.09523809523809525, 'support': 59}, 'aid_centers': {'precision': 0.4, 'recall': 0.019417475728155338, 'f1-score': 0.037037037037037035, 'support': 103}, 'other_infrastructure': {'precision': 0.32142857142857145, 'recall': 0.06521739130434782, 'f1-score': 0.10843373493975904, 'support': 276}, 'weather_related': {'precision': 0.8210116731517509, 'recall': 0.7023968042609854, 'f1-score': 0.757086472909939, 'support': 1502}, 'floods': {'precision': 0.8356164383561644, 'recall': 0.5236051502145923, 'f1-score': 0.6437994722955145, 'support': 466}, 'storm': {'precision': 0.7416879795396419, 'recall': 0.5350553505535055, 'f1-score': 0.6216505894962486, 'support': 542}, 'fire': {'precision': 0.8, 'recall': 0.1839080459770115, 'f1-score': 0.29906542056074764, 'support': 87}, 'earthquake': {'precision': 0.8977556109725686, 'recall': 0.6936416184971098, 'f1-score': 0.7826086956521738, 'support': 519}, 'cold': {'precision': 0.6833333333333333, 'recall': 0.2847222222222222, 'f1-score': 0.40196078431372545, 'support': 144}, 'other_weather': {'precision': 0.4339622641509434, 'recall': 0.14241486068111456, 'f1-score': 0.21445221445221446, 'support': 323}, 'direct_report': {'precision': 0.6853055916775033, 'recall': 0.49576669802445905, 'f1-score': 0.5753275109170305, 'support': 1063}, 'micro avg': {'precision': 0.7707738600416635, 'recall': 0.5557719054242003, 'f1-score': 0.6458494957331264, 'support': 17975}, 'macro avg': {'precision': 0.6642130249504024, 'recall': 0.3053699723958444, 'f1-score': 0.38425657179224515, 'support': 17975}, 'weighted avg': {'precision': 0.7296468974889295, 'recall': 0.5557719054242003, 'f1-score': 0.6077027788696882, 'support': 17975}, 'samples avg': {'precision': 0.6007772320252237, 'recall': 0.48837031560069893, 'f1-score': 0.49159839855617204, 'support': 17975}}
